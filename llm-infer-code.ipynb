{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71398374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:02:44.610135Z",
     "iopub.status.busy": "2023-10-06T02:02:44.609056Z",
     "iopub.status.idle": "2023-10-06T02:03:20.875597Z",
     "shell.execute_reply": "2023-10-06T02:03:20.874398Z"
    },
    "papermill": {
     "duration": 36.277852,
     "end_time": "2023-10-06T02:03:20.878051",
     "exception": false,
     "start_time": "2023-10-06T02:02:44.600199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./datasets-2.14.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.23.5)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (11.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (1.5.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (4.65.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (2023.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.14.4) (6.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.14.4) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.4) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.14.4) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.4) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.14.4) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.14.4) (1.16.0)\r\n",
      "Installing collected packages: datasets\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.1.0\r\n",
      "    Uninstalling datasets-2.1.0:\r\n",
      "      Successfully uninstalled datasets-2.1.0\r\n",
      "Successfully installed datasets-2.14.4\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/input/datasets-wheel/datasets-2.14.4-py3-none-any.whl /kaggle/working\n",
    "!pip install  /kaggle/working/datasets-2.14.4-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4c7fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:03:20.894805Z",
     "iopub.status.busy": "2023-10-06T02:03:20.893924Z",
     "iopub.status.idle": "2023-10-06T02:05:23.341617Z",
     "shell.execute_reply": "2023-10-06T02:05:23.340400Z"
    },
    "papermill": {
     "duration": 122.458551,
     "end_time": "2023-10-06T02:05:23.343986",
     "exception": false,
     "start_time": "2023-10-06T02:03:20.885435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: faiss-gpu\r\n",
      "Successfully installed faiss-gpu-1.7.2\r\n",
      "Processing ./sentence-transformers\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.30.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.1)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.5.7)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\r\n",
      "Building wheels for collected packages: sentence-transformers\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126134 sha256=aaef9bb5b59e10e13958327c98293bbb584c7cb5ed952a5d2b1e1463fdb81180\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\r\n",
      "Successfully built sentence-transformers\r\n",
      "Installing collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-2.2.2\r\n",
      "Processing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\r\n",
      "Installing collected packages: blingfire\r\n",
      "Successfully installed blingfire-0.1.8\r\n",
      "Processing /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.30.2\r\n",
      "    Uninstalling transformers-4.30.2:\r\n",
      "      Successfully uninstalled transformers-4.30.2\r\n",
      "Successfully installed transformers-4.31.0\r\n",
      "Processing /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.4.0\r\n",
      "Processing /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl\r\n",
      "Installing collected packages: trl\r\n",
      "Successfully installed trl-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "# installing offline dependencies\n",
    "!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/working/sentence-transformers\n",
    "!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n",
    "\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900f733d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:05:23.362036Z",
     "iopub.status.busy": "2023-10-06T02:05:23.361717Z",
     "iopub.status.idle": "2023-10-06T02:05:24.391619Z",
     "shell.execute_reply": "2023-10-06T02:05:24.390196Z"
    },
    "papermill": {
     "duration": 1.04179,
     "end_time": "2023-10-06T02:05:24.394072",
     "exception": false,
     "start_time": "2023-10-06T02:05:23.352282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/retrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0afa945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:05:24.412589Z",
     "iopub.status.busy": "2023-10-06T02:05:24.411919Z",
     "iopub.status.idle": "2023-10-06T02:05:24.418381Z",
     "shell.execute_reply": "2023-10-06T02:05:24.417221Z"
    },
    "papermill": {
     "duration": 0.017933,
     "end_time": "2023-10-06T02:05:24.420699",
     "exception": false,
     "start_time": "2023-10-06T02:05:24.402766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_path is /kaggle/input/kaggle-llm-science-exam/test.csv\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    csv_path = \"/kaggle/input/gte-base-context/gte-base-valid-context-970.csv\"\n",
    "else:\n",
    "    csv_path = \"/kaggle/input/kaggle-llm-science-exam/test.csv\"\n",
    "\n",
    "print(f'csv_path is {csv_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abda1471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:05:24.439581Z",
     "iopub.status.busy": "2023-10-06T02:05:24.438980Z",
     "iopub.status.idle": "2023-10-06T02:05:24.448535Z",
     "shell.execute_reply": "2023-10-06T02:05:24.447581Z"
    },
    "papermill": {
     "duration": 0.020282,
     "end_time": "2023-10-06T02:05:24.450246",
     "exception": false,
     "start_time": "2023-10-06T02:05:24.429964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/retrive/search_document.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/retrive/search_document.py\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import blingfire as bf\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import faiss\n",
    "from faiss import write_index, read_index, read_VectorTransform\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model-id', type=str, default='model',)\n",
    "    parser.add_argument('--sim-model', default='/kaggle/input/all-minilm-l12-v2', type=str)\n",
    "    parser.add_argument('--sentence-index-path', \n",
    "                        default=\"/kaggle/input/wikipedia-202307-minilm/wikipedia_202307_MiniLM-L12_seq512_title_neg4096.index\", \n",
    "                        type=str)\n",
    "    parser.add_argument('--wiki-index-path', \n",
    "                        default=\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\", \n",
    "                        type=str)\n",
    "    parser.add_argument('--test-csv-path', \n",
    "                        default='/kaggle/input/kaggle-llm-science-exam/test.csv', \n",
    "                        type=str)\n",
    "    parser.add_argument('--save-doc-path', \n",
    "                        default=\"/kaggle/working/retrive/wikipedia_file_data0.parquet\", \n",
    "                        type=str)\n",
    "    parser.add_argument('--pca-file', \n",
    "                        default=None, \n",
    "                        type=str)\n",
    "    parser.add_argument('--device', default=0, type=int)\n",
    "    parser.add_argument('--max-length', default=512, type=int)\n",
    "    parser.add_argument('--batch-size', default=8, type=int)\n",
    "    parser.add_argument('--num-titles', default=5, type=int)\n",
    "    parser.add_argument('--query-size', default=8, type=int)\n",
    "    parser.add_argument('--weight', default=1.0, type=float)\n",
    "    args = parser.parse_args()\n",
    "    print(f\"parsed document args: {args}\")\n",
    "    \n",
    "    trn = pd.read_csv(args.test_csv_path)#.drop(\"id\", 1)\n",
    "    trn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n",
    "    ## Search using the prompt and answers to guide the search\n",
    "    trn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']\n",
    "    \n",
    "    print(f\"{args.model_id}-01 load sentence model dir is {args.sim_model}!\")\n",
    "    model = SentenceTransformer(args.sim_model, device='cuda')\n",
    "    model.max_seq_length = args.max_length\n",
    "    model = model.half()\n",
    "    \n",
    "    ### load sentence index\n",
    "    print(f\"{args.model_id}-02 load sentence index path is {args.sentence_index_path}!\")\n",
    "    res = faiss.StandardGpuResources()\n",
    "    sentence_index = read_index(args.sentence_index_path)\n",
    "    sentence_index_gpu = faiss.index_cpu_to_gpu(res, 0, sentence_index)\n",
    "    ## Save memory - delete sentence_index since it is no longer necessary\n",
    "    del sentence_index\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "\n",
    "    ### extract prompt embedding\n",
    "    print(f\"{args.model_id}-03 extract prompt embedding!\")\n",
    "    prompt_embeddings = model.encode(\n",
    "        trn.prompt_answer_stem.values, \n",
    "        batch_size=args.batch_size, \n",
    "        device=args.device, \n",
    "        show_progress_bar=True, \n",
    "        convert_to_tensor=True, \n",
    "        normalize_embeddings=True)\n",
    "    prompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n",
    "    prompt_embeddings = np.asarray(prompt_embeddings.astype('float32'))\n",
    "    _ = gc.collect()\n",
    "    if args.pca_file:\n",
    "        print('use pca.')\n",
    "        pca_mat = read_VectorTransform(args.pca_file)\n",
    "        prompt_embeddings = pca_mat.apply_py(prompt_embeddings)\n",
    "    else:\n",
    "        print('No pca.')\n",
    "    search_score = []\n",
    "    search_index = []\n",
    "    total = prompt_embeddings.shape[0]\n",
    "    for i in tqdm(range(0, total, args.query_size)):\n",
    "        ss, si = sentence_index_gpu.search(prompt_embeddings[i:i+args.query_size], args.num_titles)\n",
    "        search_score.append(ss)\n",
    "        search_index.append(si)\n",
    "    search_score = np.concatenate(search_score)\n",
    "    search_index = np.concatenate(search_index)\n",
    "    ## Save memory - delete sentence_index since it is no longer necessary\n",
    "    del sentence_index_gpu\n",
    "    del prompt_embeddings\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "\n",
    "    df = pd.read_parquet(args.wiki_index_path,columns=['id', 'file'])\n",
    "    ## Get the article and associated file location using the index\n",
    "    print(f\"{args.model_id}-04 get the article and associated file location using the index!\")\n",
    "    wikipedia_file_data = []\n",
    "    for i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n",
    "        scr_idx = idx\n",
    "        _df = df.loc[scr_idx].copy()\n",
    "        _df['prompt_id'] = i #样本ID\n",
    "        _df['score'] = scr \n",
    "        wikipedia_file_data.append(_df)\n",
    "    #wikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\n",
    "    #wikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id'])\n",
    "    #wikipedia_file_data = wikipedia_file_data.reset_index(drop=True)\n",
    "    #wikipedia_file_data.to_parquet(args.save_doc_path)\n",
    "    wikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\n",
    "    wikipedia_file_data['weight'] = args.weight\n",
    "    wikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'score']]\n",
    "    wikipedia_file_data.to_parquet(f\"/kaggle/working/retrive/doc_{args.sentence_index_path.split('/')[-1].split('.')[0]}.parquet\")\n",
    "    print(f\"/kaggle/working/retrive/doc_{args.sentence_index_path.split('/')[-1].split('.')[0]}.parquet\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1ad5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:05:24.467560Z",
     "iopub.status.busy": "2023-10-06T02:05:24.466759Z",
     "iopub.status.idle": "2023-10-06T02:07:22.419418Z",
     "shell.execute_reply": "2023-10-06T02:07:22.418202Z"
    },
    "papermill": {
     "duration": 117.963759,
     "end_time": "2023-10-06T02:07:22.421759",
     "exception": false,
     "start_time": "2023-10-06T02:05:24.458000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed document args: Namespace(model_id='all-minilm-l12-v2-neg4096', sim_model='/kaggle/input/all-minilm-l12-v2', sentence_index_path='/kaggle/input/wikipedia-202307-minilm/wikipedia_202307_MiniLM-L12_seq512_title_neg4096.index', wiki_index_path='/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.77075)\r\n",
      "all-minilm-l12-v2-neg4096-01 load sentence model dir is /kaggle/input/all-minilm-l12-v2!\r\n",
      "all-minilm-l12-v2-neg4096-02 load sentence index path is /kaggle/input/wikipedia-202307-minilm/wikipedia_202307_MiniLM-L12_seq512_title_neg4096.index!\r\n",
      "all-minilm-l12-v2-neg4096-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:02<00:00,  9.48it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  8.27it/s]\r\n",
      "all-minilm-l12-v2-neg4096-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1027.46it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_202307_MiniLM-L12_seq512_title_neg4096.parquet\r\n"
     ]
    }
   ],
   "source": [
    "#all-minilm-l12-v2-neg4096 \n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'all-minilm-l12-v2-neg4096' \\\n",
    "--sim-model \"/kaggle/input/all-minilm-l12-v2\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-202307-minilm/wikipedia_202307_MiniLM-L12_seq512_title_neg4096.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.77075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b813e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:07:22.443638Z",
     "iopub.status.busy": "2023-10-06T02:07:22.443264Z",
     "iopub.status.idle": "2023-10-06T02:14:03.503800Z",
     "shell.execute_reply": "2023-10-06T02:14:03.502575Z"
    },
    "papermill": {
     "duration": 401.074377,
     "end_time": "2023-10-06T02:14:03.506162",
     "exception": false,
     "start_time": "2023-10-06T02:07:22.431785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed document args: Namespace(model_id='gte-large', sim_model='/kaggle/input/gte-large', sentence_index_path='/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part1.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part1.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.90725)\r\n",
      "gte-large-01 load sentence model dir is /kaggle/input/gte-large!\r\n",
      "gte-large-02 load sentence index path is /kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part1.index!\r\n",
      "gte-large-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  4.02it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 28.60it/s]\r\n",
      "gte-large-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1034.63it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-large_seq512_title_pos768_part1.parquet\r\n",
      "parsed document args: Namespace(model_id='gte-large', sim_model='/kaggle/input/gte-large', sentence_index_path='/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part2.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part2.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.90725)\r\n",
      "gte-large-01 load sentence model dir is /kaggle/input/gte-large!\r\n",
      "gte-large-02 load sentence index path is /kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part2.index!\r\n",
      "gte-large-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  3.96it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 29.39it/s]\r\n",
      "gte-large-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1036.75it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-large_seq512_title_pos768_part2.parquet\r\n",
      "parsed document args: Namespace(model_id='gte-large', sim_model='/kaggle/input/gte-large', sentence_index_path='/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part3.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part3.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.90725)\r\n",
      "gte-large-01 load sentence model dir is /kaggle/input/gte-large!\r\n",
      "gte-large-02 load sentence index path is /kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part3.index!\r\n",
      "gte-large-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  3.97it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 32.34it/s]\r\n",
      "gte-large-04 get the article and associated file location using the index!\r\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 956.01it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-large_seq512_title_pos768_part3.parquet\r\n",
      "parsed document args: Namespace(model_id='gte-large', sim_model='/kaggle/input/gte-large', sentence_index_path='/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part4.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part4.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.90725)\r\n",
      "gte-large-01 load sentence model dir is /kaggle/input/gte-large!\r\n",
      "gte-large-02 load sentence index path is /kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part4.index!\r\n",
      "gte-large-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  4.08it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 30.25it/s]\r\n",
      "gte-large-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1031.81it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-large_seq512_title_pos768_part4.parquet\r\n"
     ]
    }
   ],
   "source": [
    "#gte-large\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-large' \\\n",
    "--sim-model \"/kaggle/input/gte-large\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part1.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part1.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.90725\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-large' \\\n",
    "--sim-model \"/kaggle/input/gte-large\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part2.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part2.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.90725\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-large' \\\n",
    "--sim-model \"/kaggle/input/gte-large\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part3.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part3.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.90725\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-large' \\\n",
    "--sim-model \"/kaggle/input/gte-large\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-large-index/wikipedia_gte-large_seq512_title_pos768_part4.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part4.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.90725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e32dfc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:14:03.545511Z",
     "iopub.status.busy": "2023-10-06T02:14:03.544897Z",
     "iopub.status.idle": "2023-10-06T02:20:44.093384Z",
     "shell.execute_reply": "2023-10-06T02:20:44.091735Z"
    },
    "papermill": {
     "duration": 400.572563,
     "end_time": "2023-10-06T02:20:44.096134",
     "exception": false,
     "start_time": "2023-10-06T02:14:03.523571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed document args: Namespace(model_id='all-roberta-large-v1', sim_model='/kaggle/input/all-roberta-large-v1', sentence_index_path='/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part1.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part1.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.84375)\r\n",
      "all-roberta-large-v1-01 load sentence model dir is /kaggle/input/all-roberta-large-v1!\r\n",
      "all-roberta-large-v1-02 load sentence index path is /kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part1.index!\r\n",
      "all-roberta-large-v1-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  3.99it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 28.98it/s]\r\n",
      "all-roberta-large-v1-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1002.48it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part1.parquet\r\n",
      "parsed document args: Namespace(model_id='all-roberta-large-v1', sim_model='/kaggle/input/all-roberta-large-v1', sentence_index_path='/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part2.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part2.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.84375)\r\n",
      "all-roberta-large-v1-01 load sentence model dir is /kaggle/input/all-roberta-large-v1!\r\n",
      "all-roberta-large-v1-02 load sentence index path is /kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part2.index!\r\n",
      "all-roberta-large-v1-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  4.03it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 29.33it/s]\r\n",
      "all-roberta-large-v1-04 get the article and associated file location using the index!\r\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 969.78it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part2.parquet\r\n",
      "parsed document args: Namespace(model_id='all-roberta-large-v1', sim_model='/kaggle/input/all-roberta-large-v1', sentence_index_path='/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part3.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part3.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.84375)\r\n",
      "all-roberta-large-v1-01 load sentence model dir is /kaggle/input/all-roberta-large-v1!\r\n",
      "all-roberta-large-v1-02 load sentence index path is /kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part3.index!\r\n",
      "all-roberta-large-v1-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  3.98it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 32.31it/s]\r\n",
      "all-roberta-large-v1-04 get the article and associated file location using the index!\r\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 953.49it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part3.parquet\r\n",
      "parsed document args: Namespace(model_id='all-roberta-large-v1', sim_model='/kaggle/input/all-roberta-large-v1', sentence_index_path='/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part4.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part4.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.84375)\r\n",
      "all-roberta-large-v1-01 load sentence model dir is /kaggle/input/all-roberta-large-v1!\r\n",
      "all-roberta-large-v1-02 load sentence index path is /kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part4.index!\r\n",
      "all-roberta-large-v1-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:06<00:00,  3.93it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 30.09it/s]\r\n",
      "all-roberta-large-v1-04 get the article and associated file location using the index!\r\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 974.22it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part4.parquet\r\n"
     ]
    }
   ],
   "source": [
    "#all-roberta-large-v1\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'all-roberta-large-v1' \\\n",
    "--sim-model \"/kaggle/input/all-roberta-large-v1\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part1.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part1.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.84375\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'all-roberta-large-v1' \\\n",
    "--sim-model \"/kaggle/input/all-roberta-large-v1\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part2.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part2.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.84375\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'all-roberta-large-v1' \\\n",
    "--sim-model \"/kaggle/input/all-roberta-large-v1\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part3.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part3.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.84375\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'all-roberta-large-v1' \\\n",
    "--sim-model \"/kaggle/input/all-roberta-large-v1\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-all-roberta-large-v1-index/wikipedia_all-roberta-large-v1_seq512_title_pos768_part4.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part4.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.84375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d1e6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:20:44.152760Z",
     "iopub.status.busy": "2023-10-06T02:20:44.151713Z",
     "iopub.status.idle": "2023-10-06T02:24:51.754564Z",
     "shell.execute_reply": "2023-10-06T02:24:51.753295Z"
    },
    "papermill": {
     "duration": 247.63289,
     "end_time": "2023-10-06T02:24:51.756977",
     "exception": false,
     "start_time": "2023-10-06T02:20:44.124087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed document args: Namespace(model_id='gte-base', sim_model='/kaggle/input/gte-base', sentence_index_path='/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part1.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part1.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.91225)\r\n",
      "gte-base-01 load sentence model dir is /kaggle/input/gte-base!\r\n",
      "gte-base-02 load sentence index path is /kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part1.index!\r\n",
      "gte-base-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:01<00:00, 15.30it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 31.95it/s]\r\n",
      "gte-base-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1004.09it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-base_seq512_title_pos1280_part1.parquet\r\n",
      "parsed document args: Namespace(model_id='gte-base', sim_model='/kaggle/input/gte-base', sentence_index_path='/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part2.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part2.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.91225)\r\n",
      "gte-base-01 load sentence model dir is /kaggle/input/gte-base!\r\n",
      "gte-base-02 load sentence index path is /kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part2.index!\r\n",
      "gte-base-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:01<00:00, 15.19it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 32.20it/s]\r\n",
      "gte-base-04 get the article and associated file location using the index!\r\n",
      "100%|███████████████████████████████████████| 200/200 [00:00<00:00, 1043.57it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-base_seq512_title_pos1280_part2.parquet\r\n",
      "parsed document args: Namespace(model_id='gte-base', sim_model='/kaggle/input/gte-base', sentence_index_path='/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part3.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part3.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.91225)\r\n",
      "gte-base-01 load sentence model dir is /kaggle/input/gte-base!\r\n",
      "gte-base-02 load sentence index path is /kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part3.index!\r\n",
      "gte-base-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:01<00:00, 15.36it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 36.00it/s]\r\n",
      "gte-base-04 get the article and associated file location using the index!\r\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 988.64it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-base_seq512_title_pos1280_part3.parquet\r\n",
      "parsed document args: Namespace(model_id='gte-base', sim_model='/kaggle/input/gte-base', sentence_index_path='/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part4.index', wiki_index_path='/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part4.parquet', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_doc_path='/kaggle/working/retrive/wikipedia_file_data0.parquet', pca_file=None, device=0, max_length=512, batch_size=8, num_titles=3, query_size=8, weight=0.91225)\r\n",
      "gte-base-01 load sentence model dir is /kaggle/input/gte-base!\r\n",
      "gte-base-02 load sentence index path is /kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part4.index!\r\n",
      "gte-base-03 extract prompt embedding!\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:01<00:00, 15.44it/s]\r\n",
      "No pca.\r\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 33.40it/s]\r\n",
      "gte-base-04 get the article and associated file location using the index!\r\n",
      "100%|████████████████████████████████████████| 200/200 [00:00<00:00, 647.29it/s]\r\n",
      "/kaggle/working/retrive/doc_wikipedia_gte-base_seq512_title_pos1280_part4.parquet\r\n"
     ]
    }
   ],
   "source": [
    "#gte-base-pos1280\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-base' \\\n",
    "--sim-model \"/kaggle/input/gte-base\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part1.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part1.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.91225\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-base' \\\n",
    "--sim-model \"/kaggle/input/gte-base\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part2.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part2.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.91225\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-base' \\\n",
    "--sim-model \"/kaggle/input/gte-base\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part3.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part3.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.91225\n",
    "\n",
    "!python /kaggle/working/retrive/search_document.py \\\n",
    "--model-id 'gte-base' \\\n",
    "--sim-model \"/kaggle/input/gte-base\" \\\n",
    "--sentence-index-path \"/kaggle/input/wikipedia-gte-base-pos1280-index/wikipedia_gte-base_seq512_title_pos1280_part4.index\" \\\n",
    "--wiki-index-path \"/kaggle/input/wikipedia-index-quarters/wiki_2023_index_part4.parquet\" \\\n",
    "--test-csv-path {csv_path} \\\n",
    "--num-titles 3 \\\n",
    "--weight 0.91225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359f3fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:24:51.818028Z",
     "iopub.status.busy": "2023-10-06T02:24:51.817669Z",
     "iopub.status.idle": "2023-10-06T02:24:51.826465Z",
     "shell.execute_reply": "2023-10-06T02:24:51.825263Z"
    },
    "papermill": {
     "duration": 0.041282,
     "end_time": "2023-10-06T02:24:51.828456",
     "exception": false,
     "start_time": "2023-10-06T02:24:51.787174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/retrive/merge_document.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/retrive/merge_document.py\n",
    "#### merge document \n",
    "import pandas as pd\n",
    "\n",
    "EACH_TOPK = 5\n",
    "TOTAL_TOPK = 15\n",
    "\n",
    "docs = []\n",
    "save_dir = f'/kaggle/working/retrive/'\n",
    "df = pd.read_parquet(f'{save_dir}/doc_wikipedia_202307_MiniLM-L12_seq512_title_neg4096.parquet')\n",
    "idx = df.groupby(['prompt_id'])['score'].nlargest(EACH_TOPK).reset_index()['level_1']\n",
    "df = df.loc[idx].reset_index(drop=True)\n",
    "df['weight'] = 0.77075\n",
    "docs.append(df)\n",
    "\n",
    "df1 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-large_seq512_title_pos768_part1.parquet')\n",
    "df2 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-large_seq512_title_pos768_part2.parquet')\n",
    "df3 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-large_seq512_title_pos768_part3.parquet')\n",
    "df4 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-large_seq512_title_pos768_part4.parquet')\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "df['weight'] = 0.90725\n",
    "idx = df.groupby(['prompt_id'])['score'].nlargest(EACH_TOPK).reset_index()['level_1']\n",
    "df = df.loc[idx].reset_index(drop=True)\n",
    "docs.append(df)\n",
    "\n",
    "df1 = pd.read_parquet(f'{save_dir}/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part1.parquet')\n",
    "df2 = pd.read_parquet(f'{save_dir}/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part2.parquet')\n",
    "df3 = pd.read_parquet(f'{save_dir}/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part3.parquet')\n",
    "df4 = pd.read_parquet(f'{save_dir}/doc_wikipedia_all-roberta-large-v1_seq512_title_pos768_part4.parquet')\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "df['weight'] = 0.84375\n",
    "idx = df.groupby(['prompt_id'])['score'].nlargest(EACH_TOPK).reset_index()['level_1']\n",
    "df = df.loc[idx].reset_index(drop=True)\n",
    "docs.append(df)\n",
    "\n",
    "df1 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-base_seq512_title_pos1280_part1.parquet')\n",
    "df2 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-base_seq512_title_pos1280_part2.parquet')\n",
    "df3 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-base_seq512_title_pos1280_part3.parquet')\n",
    "df4 = pd.read_parquet(f'{save_dir}/doc_wikipedia_gte-base_seq512_title_pos1280_part4.parquet')\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "idx = df.groupby(['prompt_id'])['score'].nlargest(EACH_TOPK).reset_index()['level_1']\n",
    "df = df.loc[idx].reset_index(drop=True)\n",
    "df['weight'] = 0.91225\n",
    "docs.append(df)\n",
    "\n",
    "data = pd.concat(docs, ignore_index=True)\n",
    "data_with_final_score = data.groupby(['prompt_id', 'id'])['score'].agg('sum').reset_index()\n",
    "idx = data_with_final_score.groupby(['prompt_id'])['score'].nlargest(TOTAL_TOPK).reset_index()['level_1']\n",
    "topk = data_with_final_score.loc[idx].reset_index(drop=True)\n",
    "\n",
    "wikipedia_file_data = topk[['id', 'prompt_id', 'score']]\n",
    "wikipedia_file_data.to_parquet(f\"/kaggle/working/retrive/ensemble_document.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40040691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:24:51.888949Z",
     "iopub.status.busy": "2023-10-06T02:24:51.888112Z",
     "iopub.status.idle": "2023-10-06T02:24:54.736035Z",
     "shell.execute_reply": "2023-10-06T02:24:54.734472Z"
    },
    "papermill": {
     "duration": 2.881054,
     "end_time": "2023-10-06T02:24:54.739039",
     "exception": false,
     "start_time": "2023-10-06T02:24:51.857985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python /kaggle/working/retrive/merge_document.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ead769d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:24:54.806524Z",
     "iopub.status.busy": "2023-10-06T02:24:54.806093Z",
     "iopub.status.idle": "2023-10-06T02:24:54.818579Z",
     "shell.execute_reply": "2023-10-06T02:24:54.817569Z"
    },
    "papermill": {
     "duration": 0.048362,
     "end_time": "2023-10-06T02:24:54.820507",
     "exception": false,
     "start_time": "2023-10-06T02:24:54.772145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/retrive/split_sentence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/retrive/split_sentence.py\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import blingfire as bf\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import faiss\n",
    "from faiss import write_index, read_index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "def process_documents(documents: Iterable[str],\n",
    "                      document_ids: Iterable,\n",
    "                      split_sentences: bool = True,\n",
    "                      filter_len: int = 3,\n",
    "                      disable_progress_bar: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main helper function to process documents from the EMR.\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param document_type: String denoting the document type to be processed\n",
    "    :param document_sections: List of sections for a given document type to process\n",
    "    :param split_sentences: Flag to determine whether to further split sections into sentences\n",
    "    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n",
    "    :param disable_progress_bar: Flag to disable tqdm progress bar\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n",
    "    \"\"\"\n",
    "    \n",
    "    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n",
    "\n",
    "    if split_sentences:\n",
    "        df = sentencize(df.text.values, \n",
    "                        df.document_id.values,\n",
    "                        df.offset.values, \n",
    "                        filter_len, \n",
    "                        disable_progress_bar)\n",
    "    return df\n",
    "\n",
    "def sectionize_documents(documents: Iterable[str],\n",
    "                         document_ids: Iterable,\n",
    "                         disable_progress_bar: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtains the sections of the imaging reports and returns only the \n",
    "    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param disable_progress_bar: Flag to disable tqdm progress bar\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n",
    "    \"\"\"\n",
    "    processed_documents = []\n",
    "    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n",
    "        row = {}\n",
    "        text, start, end = (document, 0, len(document))\n",
    "        row['document_id'] = document_id\n",
    "        row['text'] = text\n",
    "        row['offset'] = (start, end)\n",
    "\n",
    "        processed_documents.append(row)\n",
    "\n",
    "    _df = pd.DataFrame(processed_documents)\n",
    "    if _df.shape[0] > 0:\n",
    "        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n",
    "    else:\n",
    "        return _df\n",
    "    \n",
    "def sentencize(documents: Iterable[str],\n",
    "               document_ids: Iterable,\n",
    "               offsets: Iterable[tuple[int, int]],\n",
    "               filter_len: int = 3,\n",
    "               disable_progress_bar: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Split a document into sentences. Can be used with `sectionize_documents`\n",
    "    to further split documents into more manageable pieces. Takes in offsets\n",
    "    to ensure that after splitting, the sentences can be matched to the\n",
    "    location in the original documents.\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param offsets: Iterable tuple of the start and end indices\n",
    "    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n",
    "    \"\"\"\n",
    "\n",
    "    document_sentences = []\n",
    "    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n",
    "        try:\n",
    "            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n",
    "            for o in sentence_offsets:\n",
    "                if o[1]-o[0] > filter_len:\n",
    "                    sentence = document[o[0]:o[1]]\n",
    "                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n",
    "                    row = {}\n",
    "                    row['document_id'] = document_id\n",
    "                    row['text'] = sentence\n",
    "                    row['offset'] = abs_offsets\n",
    "                    document_sentences.append(row)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame(document_sentences)\n",
    "\n",
    "def main():\n",
    "    wikipedia_file_data = pd.read_parquet('/kaggle/working/retrive/ensemble_document.parquet')\n",
    "    wiki_2023_index = pd.read_parquet('/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet',columns=['id'])\n",
    "    wiki_2023_index['num_idx'] = range(len(wiki_2023_index))\n",
    "    wiki_2023_index = wiki_2023_index[wiki_2023_index['id'].isin(wikipedia_file_data['id'])].reset_index(drop=True)\n",
    "    #wikipedia_file_data['file'] = wikipedia_file_data['id'].map(wiki_2023_index.set_index(['id'])['file'])\n",
    "    wikipedia_file_data['num_idx'] = wikipedia_file_data['id'].map(wiki_2023_index.set_index(['id'])['num_idx'])\n",
    "    all_indeces = list(wikipedia_file_data['num_idx'])\n",
    "    wikipedia_file_data = wikipedia_file_data[['id', 'prompt_id']].drop_duplicates().sort_values(['id']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    wiki_text_data = pd.read_parquet('/kaggle/input/wiki-2023-index-partition/wiki_2023_all.parquet',\n",
    "                                  engine='pyarrow',\n",
    "                                  filters=[('index', 'in', all_indeces)],\n",
    "                                  columns=['index', 'id', 'text'])\n",
    "    del wiki_text_data['index']\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "\n",
    "    ## Parse documents into sentences\n",
    "    processed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)\n",
    "\n",
    "    processed_wiki_text_data['loc'] = 1\n",
    "    processed_wiki_text_data['location'] = processed_wiki_text_data.groupby(['document_id'])['loc'].transform('cumsum')\n",
    "\n",
    "    del processed_wiki_text_data['loc']\n",
    "    processed_wiki_text_data.to_parquet('/kaggle/working/retrive/processed_wiki_text_data.parquet', index=False)#document_id, \n",
    "    wikipedia_file_data.to_parquet('/kaggle/working/retrive/wikipedia_file_data.parquet', index=False)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba871cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:24:54.885258Z",
     "iopub.status.busy": "2023-10-06T02:24:54.884904Z",
     "iopub.status.idle": "2023-10-06T02:27:00.088510Z",
     "shell.execute_reply": "2023-10-06T02:27:00.087067Z"
    },
    "papermill": {
     "duration": 125.238701,
     "end_time": "2023-10-06T02:27:00.090963",
     "exception": false,
     "start_time": "2023-10-06T02:24:54.852262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "100%|███████████████████████████████████| 1921/1921 [00:00<00:00, 772878.46it/s]\r\n",
      "100%|██████████████████████████████████████| 1921/1921 [00:09<00:00, 193.04it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/retrive/split_sentence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62aaece9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:27:00.161944Z",
     "iopub.status.busy": "2023-10-06T02:27:00.161597Z",
     "iopub.status.idle": "2023-10-06T02:27:00.170067Z",
     "shell.execute_reply": "2023-10-06T02:27:00.169077Z"
    },
    "papermill": {
     "duration": 0.045788,
     "end_time": "2023-10-06T02:27:00.172338",
     "exception": false,
     "start_time": "2023-10-06T02:27:00.126550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/retrive/search_sentence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/retrive/search_sentence.py\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import blingfire as bf\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import faiss\n",
    "from faiss import write_index, read_index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--sim-model', default='/kaggle/input/multi-qa-mpnet-base-cos-v1', type=str)\n",
    "    parser.add_argument('--wiki-path', default='/kaggle/input/wikipedia-20230701', type=str)\n",
    "    parser.add_argument('--test-csv-path', \n",
    "                        default='/kaggle/input/kaggle-llm-science-exam/test.csv', \n",
    "                        type=str)\n",
    "    parser.add_argument('--save-sentence-path', \n",
    "                        default=\"/kaggle/working/retrive/sentence.parquet\", \n",
    "                        type=str)\n",
    "    parser.add_argument('--device', default=0, type=int)\n",
    "    parser.add_argument('--max-length', default=384, type=int)\n",
    "    parser.add_argument('--batch-size', default=8, type=int)\n",
    "    parser.add_argument('--num-sentences', default=60, type=int)\n",
    "    args = parser.parse_args()\n",
    "    print(f\"parsed sentence args: {args}\")\n",
    "    \n",
    "    trn = pd.read_csv(args.test_csv_path)\n",
    "    ## Combine all answers\n",
    "    trn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n",
    "    ## Search using the prompt and answers to guide the search\n",
    "    trn['prompt_answer_stem'] = trn['prompt']+ \" \" + trn['answer_all']\n",
    "\n",
    "    model = SentenceTransformer(args.sim_model, device='cuda')\n",
    "    model.max_seq_length = args.max_length\n",
    "    model = model.half()\n",
    "    \n",
    "    ## Parse documents into sentences\n",
    "    processed_wiki_text_data = pd.read_parquet('/kaggle/working/retrive/processed_wiki_text_data.parquet')\n",
    "    wikipedia_file_data = pd.read_parquet('/kaggle/working/retrive/wikipedia_file_data.parquet') \n",
    "    ## Get embeddings of the wiki text data\n",
    "    wiki_data_embeddings = model.encode(processed_wiki_text_data.text,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        device=args.device,\n",
    "                                        show_progress_bar=True,\n",
    "                                        convert_to_tensor=True,\n",
    "                                        normalize_embeddings=True)#.half()\n",
    "    wiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()\n",
    "    wiki_data_embeddings = np.asarray(wiki_data_embeddings.astype('float32'))\n",
    "    _ = gc.collect()\n",
    "\n",
    "    question_embeddings = model.encode(\n",
    "        trn.prompt_answer_stem.values, \n",
    "        batch_size=args.batch_size, \n",
    "        device=args.device, \n",
    "        show_progress_bar=True, \n",
    "        convert_to_tensor=True, \n",
    "        normalize_embeddings=True)\n",
    "    question_embeddings = question_embeddings.detach().cpu().numpy()\n",
    "    question_embeddings = np.asarray(question_embeddings.astype('float32'))\n",
    "\n",
    "    sentences = []\n",
    "    for r in tqdm(trn.itertuples(), total=len(trn)):\n",
    "        prompt_id = r.Index\n",
    "        prompt_answer_stem = r.prompt_answer_stem\n",
    "        prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n",
    "        if prompt_indices.shape[0] > 0:\n",
    "            prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n",
    "            prompt_index.add(wiki_data_embeddings[prompt_indices])\n",
    "            ## Get the top matches\n",
    "            ss, ii = prompt_index.search(question_embeddings, args.num_sentences)\n",
    "            for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n",
    "                sentences.append([prompt_id, prompt_answer_stem, processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i]])\n",
    "    pd.DataFrame(sentences, columns=['prompt_id', 'prompt_answer_stem', 'text']).to_parquet(args.save_sentence_path, index=False)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4501f375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:27:00.240829Z",
     "iopub.status.busy": "2023-10-06T02:27:00.240479Z",
     "iopub.status.idle": "2023-10-06T02:29:30.101776Z",
     "shell.execute_reply": "2023-10-06T02:29:30.100383Z"
    },
    "papermill": {
     "duration": 149.897954,
     "end_time": "2023-10-06T02:29:30.104199",
     "exception": false,
     "start_time": "2023-10-06T02:27:00.206245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed sentence args: Namespace(sim_model='/kaggle/input/sentencetransformer-hubs/all-MiniLM-L6-v2', wiki_path='/kaggle/input/wikipedia-20230701', test_csv_path='/kaggle/input/kaggle-llm-science-exam/test.csv', save_sentence_path='/kaggle/working/retrive/sentence_all-MiniLM-L6-v2.parquet', device=0, max_length=384, batch_size=8, num_sentences=60)\r\n",
      "Batches: 100%|███████████████████████████| 13666/13666 [02:01<00:00, 112.28it/s]\r\n",
      "Batches: 100%|██████████████████████████████████| 25/25 [00:00<00:00, 71.09it/s]\r\n",
      "100%|█████████████████████████████████████████| 200/200 [00:09<00:00, 21.42it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/retrive/search_sentence.py \\\n",
    "--sim-model \"/kaggle/input/sentencetransformer-hubs/all-MiniLM-L6-v2\" \\\n",
    "--save-sentence-path \"/kaggle/working/retrive/sentence_all-MiniLM-L6-v2.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4481a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:29:30.292975Z",
     "iopub.status.busy": "2023-10-06T02:29:30.292625Z",
     "iopub.status.idle": "2023-10-06T02:29:30.301558Z",
     "shell.execute_reply": "2023-10-06T02:29:30.300618Z"
    },
    "papermill": {
     "duration": 0.105214,
     "end_time": "2023-10-06T02:29:30.303387",
     "exception": false,
     "start_time": "2023-10-06T02:29:30.198173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/retrive/rerank.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/retrive/rerank.py\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import blingfire as bf\n",
    "\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import faiss\n",
    "from faiss import write_index, read_index\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "\n",
    "RERANK_MODEL_NAME = '/kaggle/input/all-mpnet-base-v2'\n",
    "SEN_RERANK_MODEL = '/kaggle/input/rank-cls/si_all_mpnet_base_v2_len_512_bin_cls/model.pth'\n",
    "RANK_THRESOLD = 0.65\n",
    "DEVICE = 0\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(RERANK_MODEL_NAME)\n",
    "tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class TextPairDataset(Dataset):\n",
    "    def __init__(self, text1, text2, tokenizer, target=None, max_len=512) -> None:\n",
    "        self.text1 = text1\n",
    "        self.text2 = text2\n",
    "        self.target = target\n",
    "        self.tokenzer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        t1 = self.text1[index]\n",
    "        t2 = self.text2[index]\n",
    "        tg = self.target[index] if self.target is not None else -1\n",
    "        ret = self.tokenzer(t1,t2,\n",
    "                            truncation=True,\n",
    "                            max_length=self.max_len)\n",
    "        ret[\"labels\"] = tg\n",
    "        return ret\n",
    "    \n",
    "class RankModel(nn.Module):\n",
    "    def __init__(self, model_path) -> None:\n",
    "        super().__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_path)\n",
    "        self.config.update({\n",
    "            \"output_hidden_states\":True,\n",
    "            \"hidden_dropout\": 0.0,\n",
    "            \"hidden_dropout_prob\":0.0,\n",
    "            \"attention_dropout\":0.0,\n",
    "            \"attention_probs_dropout_prob\":0.0,\n",
    "            \"layer_norm_eps\": 1e-7\n",
    "        })\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_path, config=self.config)\n",
    "        \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(self.config.hidden_size, self.config.hidden_size//2),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(self.config.hidden_size//2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        context_vector = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        out = self.fc(context_vector)\n",
    "        return out\n",
    "    \n",
    "rank_model = RankModel(RERANK_MODEL_NAME)\n",
    "rank_model.load_state_dict(torch.load(SEN_RERANK_MODEL))\n",
    "rank_model.to('cuda')\n",
    "print(\"rank model name: \", RERANK_MODEL_NAME)\n",
    "print(\"load rank model from: \", SEN_RERANK_MODEL)\n",
    "\n",
    "text_pair_for_rerank_df = pd.read_parquet('/kaggle/working/retrive/sentence_all-MiniLM-L6-v2.parquet')\n",
    "\n",
    "test_ds = TextPairDataset(text_pair_for_rerank_df['prompt_answer_stem'].tolist(), text_pair_for_rerank_df['text'].tolist(), tokenizer, max_len=MAX_LENGTH)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, \n",
    "                     shuffle=False, num_workers=4, \n",
    "                     collate_fn=data_collator)\n",
    "\n",
    "def valid_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader, total=len(data_loader), desc=\"Eval: \"):\n",
    "            data = {k: v.to(device) for k, v in d.items()}\n",
    "            \n",
    "            targets = data.pop('labels')\n",
    "            \n",
    "            outputs = model(data)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            \n",
    "    return fin_outputs, fin_targets\n",
    "\n",
    "rank_preds, _ = valid_fn(test_dl, rank_model, 'cuda')\n",
    "preds = [rp[0] for rp in rank_preds]\n",
    "\n",
    "\n",
    "def get_rank_id_context(preds, val_df, thresold):\n",
    "    val_df[\"pred_probs\"] = preds\n",
    "    ensure_df = val_df.sort_values(\"pred_probs\", ascending=False).groupby([\"prompt_id\"]).head(5).reset_index(drop=True)\n",
    "    ensure_df = ensure_df.groupby([\"prompt_id\"]).agg({'text':' '.join}).reset_index()\n",
    "    ensure_df = ensure_df[[\"prompt_id\", \"text\"]]\n",
    "    ensure_df.columns = [\"prompt_id\", \"text_safe\"]\n",
    "    \n",
    "    val_df[\"pred\"] = np.where(val_df[\"pred_probs\"]>thresold, 1, 0)\n",
    "    pred_df = val_df[val_df[\"pred\"]==1].groupby(\"prompt_id\")[\"text\"].unique().reset_index()\n",
    "    pred_df[\"context\"] = pred_df[\"text\"].apply(lambda x: \" \".join(x))\n",
    "    eval_df = ensure_df.merge(pred_df, how='left', on=\"prompt_id\")\n",
    "    eval_df[\"context\"] = np.where(eval_df[\"context\"].isna(),eval_df[\"text_safe\"],eval_df[\"context\"])\n",
    "    eval_df[\"context\"] = eval_df[\"context\"].fillna(\" \")\n",
    "    eval_df = eval_df.sort_values(\"prompt_id\")\n",
    "    eval_df = eval_df.reset_index(drop=True)\n",
    "    return eval_df[\"context\"]\n",
    "\n",
    "trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")\n",
    "# trn = pd.read_csv(\"/kaggle/input/gte-base-context/gte-base-valid-context-970.csv\")\n",
    "trn['context'] = get_rank_id_context(preds, text_pair_for_rerank_df, RANK_THRESOLD)\n",
    "trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"/kaggle/working/retrive/test_context.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1638886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:29:30.540304Z",
     "iopub.status.busy": "2023-10-06T02:29:30.539987Z",
     "iopub.status.idle": "2023-10-06T02:32:12.612124Z",
     "shell.execute_reply": "2023-10-06T02:32:12.610859Z"
    },
    "papermill": {
     "duration": 162.222923,
     "end_time": "2023-10-06T02:32:12.614586",
     "exception": false,
     "start_time": "2023-10-06T02:29:30.391663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\r\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\r\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\r\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\r\n",
      "rank model name:  /kaggle/input/all-mpnet-base-v2\r\n",
      "load rank model from:  /kaggle/input/rank-cls/si_all_mpnet_base_v2_len_512_bin_cls/model.pth\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "Eval: 100%|█████████████████████████████████| 1500/1500 [02:19<00:00, 10.75it/s]\r\n"
     ]
    }
   ],
   "source": [
    "###rerank\n",
    "!python /kaggle/working/retrive/rerank.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a97432e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:32:12.866511Z",
     "iopub.status.busy": "2023-10-06T02:32:12.865389Z",
     "iopub.status.idle": "2023-10-06T02:33:49.451247Z",
     "shell.execute_reply": "2023-10-06T02:33:49.450154Z"
    },
    "papermill": {
     "duration": 96.71186,
     "end_time": "2023-10-06T02:33:49.453737",
     "exception": false,
     "start_time": "2023-10-06T02:32:12.741877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5c6954d5884f6ea4629caa1c98e3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c220551c391b421caf79f820afc5da6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a268dfe37ed04ff2af9e287897efef74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70398ecb836346f3806e874abeea320f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import blingfire as bf\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import faiss\n",
    "from faiss import write_index, read_index, read_VectorTransform\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "\n",
    "class CFG:\n",
    "    EMB_MODEL = \"/kaggle/input/gte-base\"\n",
    "    INDEX_PATH = \"/kaggle/input/wikipedia-stem-index/parsed_gte-base.index\"\n",
    "    WIKI_PARSED_PLAINTEXT_PATH = \"/kaggle/input/llm-models2/content/wikipedia-stem-plaintext/parsed.parquet\"\n",
    "    WIKI_COHERE_PLAINTEXT_PATH = \"/kaggle/input/llm-models2/content/wikipedia-stem-plaintext/cohere.parquet\"\n",
    "    \n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 32\n",
    "    MAX_DOC_NUM = 10\n",
    "    \n",
    "#     DEBUG = False\n",
    "import pandas as pd\n",
    "trn = pd.read_csv(\"/kaggle/working/retrive/test_context.csv\")\n",
    "## Combine all answers\n",
    "trn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n",
    "\n",
    "## Search using the prompt and answers to guide the search\n",
    "trn['prompt_answer_stem'] = trn['prompt'] + \" \" +trn['prompt'] + \" \" +trn['prompt'] + \" \" + trn['answer_all']\n",
    "model = SentenceTransformer(CFG.EMB_MODEL, device='cuda')\n",
    "model.max_seq_length = CFG.MAX_LENGTH\n",
    "\n",
    "\n",
    "prompt_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=CFG.BATCH_SIZE, device=0, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\n",
    "prompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "res = faiss.StandardGpuResources()\n",
    "sentence_index = read_index(CFG.INDEX_PATH)\n",
    "sentence_index_gpu = faiss.index_cpu_to_gpu(res, 0, sentence_index)\n",
    "\n",
    "QUERY_SIZE = 8\n",
    "search_score = []\n",
    "search_index = []\n",
    "total = prompt_embeddings.shape[0]\n",
    "for i in tqdm(range(0, total, QUERY_SIZE)):\n",
    "    ss, si = sentence_index_gpu.search(prompt_embeddings[i:i+QUERY_SIZE], CFG.MAX_DOC_NUM)\n",
    "    search_score.append(ss)\n",
    "    search_index.append(si)\n",
    "    \n",
    "search_score = np.concatenate(search_score)\n",
    "search_index = np.concatenate(search_index)\n",
    "\n",
    "\n",
    "## Save memory - delete sentence_index since it is no longer necessary\n",
    "del sentence_index\n",
    "del sentence_index_gpu\n",
    "del prompt_embeddings\n",
    "#del model\n",
    "_ = gc.collect()\n",
    "#torch.cuda.empty_cache()\n",
    "libc.malloc_trim(0)\n",
    "\n",
    "df = pd.read_parquet(CFG.WIKI_PARSED_PLAINTEXT_PATH,columns=['text'])\n",
    "\n",
    "contexts = []\n",
    "\n",
    "for i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n",
    "    context = \"\"\n",
    "    scr_idx = idx\n",
    "    context_list = df.loc[scr_idx].text.tolist()\n",
    "    context += \" \".join(context_list)\n",
    "    contexts.append(context)\n",
    "\n",
    "## Save memory - delete df since it is no longer necessary\n",
    "del df\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)\n",
    "\n",
    "trn['context1'] = contexts\n",
    "\n",
    "df = pd.read_parquet(CFG.WIKI_COHERE_PLAINTEXT_PATH,columns=['text'])\n",
    "\n",
    "contexts = []\n",
    "\n",
    "for i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n",
    "    context = \"\"\n",
    "    scr_idx = idx\n",
    "    context_list = df.loc[scr_idx].text.tolist()\n",
    "    context += \" \".join(context_list)\n",
    "    contexts.append(context)\n",
    "\n",
    "## Save memory - delete df since it is no longer necessary\n",
    "del df\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)\n",
    "\n",
    "trn['context2'] = contexts\n",
    "\n",
    "save_cols = [\"prompt\", \"context\", \"context1\", \"context2\", \"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "trn[save_cols].to_csv(\"/kaggle/working/retrive/test_context.csv\", index=False)\n",
    "\n",
    "del trn\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26937ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:33:49.717577Z",
     "iopub.status.busy": "2023-10-06T02:33:49.717200Z",
     "iopub.status.idle": "2023-10-06T02:34:31.865508Z",
     "shell.execute_reply": "2023-10-06T02:34:31.864318Z"
    },
    "papermill": {
     "duration": 42.411571,
     "end_time": "2023-10-06T02:34:31.994342",
     "exception": false,
     "start_time": "2023-10-06T02:33:49.582771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 model dir is /kaggle/input/llm-models2/deberta-v3-large-max-len1024-3e-311297-val971/best\n",
      "model_path is /kaggle/input/llm-models2/deberta-v3-large-max-len1024-3e-311297-val971/best/deberta-v3-large-hf-weights_foldextra_swa.pth\n",
      "Index 1 model dir is /kaggle/input/llm-models2/deberta-v3-large-max-len1024-lr5-3e-322538-val970/swa\n",
      "model_path is /kaggle/input/llm-models2/deberta-v3-large-max-len1024-lr5-3e-322538-val970/swa/deberta-v3-large-hf-weights_foldextra_swa.pth\n",
      "ensemble 2 models!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"/kaggle/working/retrive/test_context.csv\")\n",
    "test_df.index = list(range(len(test_df)))\n",
    "test_df['id'] = list(range(len(test_df)))\n",
    "test_df['answer'] = 'A'\n",
    "test_df = test_df.replace(np.NaN, 'none')\n",
    "test_df.head()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import AutoModelForMultipleChoice\n",
    "import pytorch_lightning as pl\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, config, *, dropout=0.2, pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # Transformer\n",
    "        self.config = config\n",
    "        if pretrained:\n",
    "            self.transformer = AutoModelForMultipleChoice.from_pretrained(model_dir, config=self.config)\n",
    "        else:\n",
    "            self.transformer = AutoModelForMultipleChoice.from_config(self.config)\n",
    "\n",
    "    def _init_weights(self, module, config):\n",
    "        module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        out = self.transformer(input_ids, attention_mask, token_type_ids=token_type_ids)\n",
    "        x = out['logits']\n",
    "        return x\n",
    "    \n",
    "class CustomPLModel(pl.LightningModule):\n",
    "    def __init__(self,model_dir):\n",
    "        super(CustomPLModel,self).__init__()\n",
    "        self.net = CustomModel(model_dir)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask,token_type_ids):\n",
    "        return self.net(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "    \n",
    "def load_weights(model_dir):\n",
    "    config_path = f'{model_dir}/deberta-v3-large-hf-weights_config.pth'\n",
    "    model_path = f'{model_dir}/deberta-v3-large-hf-weights_foldextra_swa.pth'\n",
    "    config = torch.load(config_path)\n",
    "    config._name_or_path = f'{model_dir}/tokenizer'\n",
    "#     print(config)\n",
    "    print(f'model_path is {model_path}')\n",
    "    \n",
    "    net = CustomPLModel(config).cuda()\n",
    "    state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)['state_dict']\n",
    "    net.load_state_dict(state_dict, strict=False)  # True\n",
    "    model = net.eval()\n",
    "    return model\n",
    "import gc\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_dir_path1 = '/kaggle/input/llm-models2/deberta-v3-large-max-len1024-3e-311297-val971/best'#lb=0.860\n",
    "#/kaggle/input/llm-models2/deberta-v3-large-max-len1024-3e-311297-val971/best/deberta-v3-large-hf-weights_config.pth\n",
    "model_dir_path2 = \"/kaggle/input/llm-models2/deberta-v3-large-max-len1024-lr5-3e-322538-val970/swa\" #lb=0.853\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{model_dir_path1}/tokenizer')\n",
    "model_dir_list = [\n",
    "    model_dir_path1,\n",
    "    model_dir_path2,\n",
    "]\n",
    "models_list = []\n",
    "for index, model_dir in enumerate(model_dir_list):\n",
    "    print(f'Index {index} model dir is {model_dir}')\n",
    "    model = load_weights(model_dir)\n",
    "    models_list.append(model)\n",
    "    del model\n",
    "    gc.collect()\n",
    "print(f'ensemble {len(models_list)} models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a08fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:32.253170Z",
     "iopub.status.busy": "2023-10-06T02:34:32.252077Z",
     "iopub.status.idle": "2023-10-06T02:34:32.259397Z",
     "shell.execute_reply": "2023-10-06T02:34:32.258565Z"
    },
    "papermill": {
     "duration": 0.138889,
     "end_time": "2023-10-06T02:34:32.261271",
     "exception": false,
     "start_time": "2023-10-06T02:34:32.122382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_INPUT = 1536\n",
    "\n",
    "class LlmseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx]\n",
    "        first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n",
    "        second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n",
    "        tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                    max_length=MAX_INPUT, add_special_tokens=False)\n",
    "        tokenized_example['label'] = self.option_to_index[example['answer']]\n",
    "            \n",
    "        return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88002219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:32.583956Z",
     "iopub.status.busy": "2023-10-06T02:34:32.583613Z",
     "iopub.status.idle": "2023-10-06T02:34:32.590453Z",
     "shell.execute_reply": "2023-10-06T02:34:32.589325Z"
    },
    "papermill": {
     "duration": 0.141645,
     "end_time": "2023-10-06T02:34:32.592259",
     "exception": false,
     "start_time": "2023-10-06T02:34:32.450614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LlmseDataset1(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx]\n",
    "        first_sentence = [ \"[CLS] \" + example['context1'] ] * 5\n",
    "        second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n",
    "        tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                    max_length=MAX_INPUT, add_special_tokens=False)\n",
    "        tokenized_example['label'] = self.option_to_index[example['answer']]\n",
    "            \n",
    "        return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "338f21b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:32.843793Z",
     "iopub.status.busy": "2023-10-06T02:34:32.842722Z",
     "iopub.status.idle": "2023-10-06T02:34:32.850168Z",
     "shell.execute_reply": "2023-10-06T02:34:32.849323Z"
    },
    "papermill": {
     "duration": 0.13386,
     "end_time": "2023-10-06T02:34:32.851914",
     "exception": false,
     "start_time": "2023-10-06T02:34:32.718054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LlmseDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx]\n",
    "        first_sentence = [ \"[CLS] \" + example['context2'] ] * 5\n",
    "        second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n",
    "        tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                    max_length=MAX_INPUT, add_special_tokens=False)\n",
    "        tokenized_example['label'] = self.option_to_index[example['answer']]\n",
    "            \n",
    "        return tokenized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f07525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:33.108680Z",
     "iopub.status.busy": "2023-10-06T02:34:33.108328Z",
     "iopub.status.idle": "2023-10-06T02:34:33.117810Z",
     "shell.execute_reply": "2023-10-06T02:34:33.116895Z"
    },
    "papermill": {
     "duration": 0.142856,
     "end_time": "2023-10-06T02:34:33.119579",
     "exception": false,
     "start_time": "2023-10-06T02:34:32.976723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50f2caa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:33.365327Z",
     "iopub.status.busy": "2023-10-06T02:34:33.364978Z",
     "iopub.status.idle": "2023-10-06T02:34:33.371862Z",
     "shell.execute_reply": "2023-10-06T02:34:33.370834Z"
    },
    "papermill": {
     "duration": 0.13214,
     "end_time": "2023-10-06T02:34:33.373507",
     "exception": false,
     "start_time": "2023-10-06T02:34:33.241367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "#### wiki document data\n",
    "test_ds = LlmseDataset(test_df)\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    collate_fn=data_collator,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    drop_last=False)\n",
    "\n",
    "\n",
    "###stem 270k parsed data\n",
    "test_ds1 = LlmseDataset1(test_df)\n",
    "test_dl1 = DataLoader(\n",
    "    test_ds1, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    collate_fn=data_collator,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    drop_last=False)\n",
    "\n",
    "###stem 270k cohere data\n",
    "test_ds2 = LlmseDataset2(test_df)\n",
    "test_dl2 = DataLoader(\n",
    "    test_ds2, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    collate_fn=data_collator,\n",
    "    num_workers=os.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "868607e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:33.622358Z",
     "iopub.status.busy": "2023-10-06T02:34:33.622012Z",
     "iopub.status.idle": "2023-10-06T02:34:33.629172Z",
     "shell.execute_reply": "2023-10-06T02:34:33.628157Z"
    },
    "papermill": {
     "duration": 0.132685,
     "end_time": "2023-10-06T02:34:33.630892",
     "exception": false,
     "start_time": "2023-10-06T02:34:33.498207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims = True) \n",
    "\n",
    "def do_inference(model,test_dl,device):\n",
    "    y_preds = []\n",
    "    with tqdm(test_dl, leave=False) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(pbar):\n",
    "                inp_ids = batch['input_ids'].to(device)\n",
    "                att_mask = batch['attention_mask'].to(device)\n",
    "                token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "                y_pred = model(input_ids=inp_ids, \n",
    "                               attention_mask=att_mask, \n",
    "                               token_type_ids=token_type_ids)\n",
    "\n",
    "                y_pred = y_pred.to(torch.float)\n",
    "                y_preds.append(y_pred.cpu())\n",
    "    preds = torch.cat(y_preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fedd142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:34:33.883395Z",
     "iopub.status.busy": "2023-10-06T02:34:33.883031Z",
     "iopub.status.idle": "2023-10-06T02:48:33.467976Z",
     "shell.execute_reply": "2023-10-06T02:48:33.459447Z"
    },
    "papermill": {
     "duration": 839.71706,
     "end_time": "2023-10-06T02:48:33.471137",
     "exception": false,
     "start_time": "2023-10-06T02:34:33.754077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7545d8b995a642648d0a2446b10dc310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697f02597abe4c368d9f28d852c8499b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afece35321fc4a789e843292023f8151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74414ee9d5c5481aa249f58b85fe717a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "all_preds = 0\n",
    "for model in models_list:\n",
    "    preds0 = do_inference(model,test_dl,device)\n",
    "    preds1 = do_inference(model,test_dl1,device)\n",
    "    #preds2 = do_inference(model,test_dl2,device)\n",
    "    preds = (softmax(preds0.numpy()) + softmax(preds1.numpy())*1.25  ) / 2.25\n",
    "    all_preds += preds\n",
    "    del model,preds0, preds1, preds\n",
    "    gc.collect()\n",
    "all_preds /= len(models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d7ac79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:48:33.919156Z",
     "iopub.status.busy": "2023-10-06T02:48:33.918724Z",
     "iopub.status.idle": "2023-10-06T02:48:33.941638Z",
     "shell.execute_reply": "2023-10-06T02:48:33.940422Z"
    },
    "papermill": {
     "duration": 0.163243,
     "end_time": "2023-10-06T02:48:33.943674",
     "exception": false,
     "start_time": "2023-10-06T02:48:33.780431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D E B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A B E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A C D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C A E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>D A C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id prediction\n",
       "0   0      D E B\n",
       "1   1      A B E\n",
       "2   2      A C D\n",
       "3   3      C A E\n",
       "4   4      D A C"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_ids = np.argsort(-all_preds, 1)\n",
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "test_df['prediction'] = [' '.join(row) for row in predictions_as_answer_letters[:, :3]]\n",
    "submission = test_df[['id', 'prediction']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26dea516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:48:34.215224Z",
     "iopub.status.busy": "2023-10-06T02:48:34.214858Z",
     "iopub.status.idle": "2023-10-06T02:48:34.222689Z",
     "shell.execute_reply": "2023-10-06T02:48:34.221440Z"
    },
    "papermill": {
     "duration": 0.146406,
     "end_time": "2023-10-06T02:48:34.224792",
     "exception": false,
     "start_time": "2023-10-06T02:48:34.078386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\n",
    "import numpy as np\n",
    "def precision_at_k(r, k):\n",
    "    \"\"\"Precision at k\"\"\"\n",
    "    assert k <= len(r)\n",
    "    assert k != 0\n",
    "    return sum(int(x) for x in r[:k]) / k\n",
    "\n",
    "def MAP_at_3(predictions, true_items):\n",
    "    \"\"\"Score is mean average precision at 3\"\"\"\n",
    "    U = len(predictions)\n",
    "    map_at_3 = 0.0\n",
    "    for u in range(U):\n",
    "        user_preds = predictions[u].split()\n",
    "        user_true = true_items[u]\n",
    "        user_results = [1 if item == user_true else 0 for item in user_preds]\n",
    "        for k in range(min(len(user_preds), 3)):\n",
    "            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n",
    "    return map_at_3 / U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df3578cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:48:34.500438Z",
     "iopub.status.busy": "2023-10-06T02:48:34.499285Z",
     "iopub.status.idle": "2023-10-06T02:48:34.530570Z",
     "shell.execute_reply": "2023-10-06T02:48:34.529414Z"
    },
    "papermill": {
     "duration": 0.171595,
     "end_time": "2023-10-06T02:48:34.532515",
     "exception": false,
     "start_time": "2023-10-06T02:48:34.360920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n"
     ]
    }
   ],
   "source": [
    "if len(submission) == 200:\n",
    "    train = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n",
    "    preds = [pred for pred in submission['prediction']]\n",
    "    print(MAP_at_3(preds, train[\"answer\"]))\n",
    "\n",
    "###cv=0.9925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87978c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T02:48:34.802520Z",
     "iopub.status.busy": "2023-10-06T02:48:34.802109Z",
     "iopub.status.idle": "2023-10-06T02:48:37.289725Z",
     "shell.execute_reply": "2023-10-06T02:48:37.288311Z"
    },
    "papermill": {
     "duration": 2.623538,
     "end_time": "2023-10-06T02:48:37.292225",
     "exception": false,
     "start_time": "2023-10-06T02:48:34.668687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/datasets-2.14.4-py3-none-any.whl\n",
    "!rm -r /kaggle/working/sentence-transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2766.511086,
   "end_time": "2023-10-06T02:48:40.943199",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-06T02:02:34.432113",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01280cd46a1a487d8720ad3c23cc04c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "01960581a4d9449a935021d8a8ad9ac5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "02aac9887b854f0695db558c0ba9d712": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "02c72da34a7344978f8b3064fcc32f15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7855ce52cb704561a6dd9d97c76c6f90",
       "placeholder": "​",
       "style": "IPY_MODEL_fae78d56058d4bd6bc1def709bab2083",
       "value": "100%"
      }
     },
     "0732790998d14bcb91f1502f880cfac8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0b200cda1b2b4e5aa039706ccd46c0ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0be1e245b01f4c06b2f5132ca502f05d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0d40abe973a440e6b55116f5a7476226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0d6218ab56554fd197dcec774219b3d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0e9d07b3f0c848c0953e7d372f263d4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b2589b41f980426893a94be34000f57d",
       "placeholder": "​",
       "style": "IPY_MODEL_e60cf39cec994282add3df3ea98d0778",
       "value": " 7/7 [00:02&lt;00:00,  4.23it/s]"
      }
     },
     "133d066ef04d4c60b421d1fae5b906f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c4351cb7f4b1482d8e7412e5d5acb115",
       "placeholder": "​",
       "style": "IPY_MODEL_0d40abe973a440e6b55116f5a7476226",
       "value": "100%"
      }
     },
     "17e9331b7ee84a95b9cfb7ceb1f2ed7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_981be822fb774e328dad0affde0cd037",
       "placeholder": "​",
       "style": "IPY_MODEL_0732790998d14bcb91f1502f880cfac8",
       "value": "100%"
      }
     },
     "17fa6f36542b4299ba7e938d4257d96e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1849c778434e407896e99bac0c263b95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_879a1e38f287402ea99c116f54729e74",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54c6d8b91a5847c99772163de0505879",
       "value": 200.0
      }
     },
     "1e36d562b7dd40d6b79786c8cbb9d52e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e81472ecd1d4618a7242ab93d5c46c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "205ff1eddc254c7fbbecbb6e9203d85f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_548dd825cc3f477aa2ad8b65f66c0cb1",
       "placeholder": "​",
       "style": "IPY_MODEL_bb814c8ac50440dca6aea9b4e190a8f5",
       "value": "Batches: 100%"
      }
     },
     "2aac2b921b0f4f659aeb8038374acc96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2e64309d471343d2b45b347484224a30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e36d562b7dd40d6b79786c8cbb9d52e",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_02aac9887b854f0695db558c0ba9d712",
       "value": 200.0
      }
     },
     "2f5a5195f30f4aed9f5af428d8fedd91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "31e04ed84ea6413ca60e08e16917c2e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cbb2cb2ab31d411dbf280c5bc7757c41",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d6218ab56554fd197dcec774219b3d3",
       "value": 200.0
      }
     },
     "37e22db016c8423e9d1d386c1cd22386": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e26bc0470d37446b9e983a8eaf890bd1",
       "placeholder": "​",
       "style": "IPY_MODEL_be8e2717e8464620aaf8c5c43aa06a4d",
       "value": "100%"
      }
     },
     "43e8d2a129ea4fb4be8411e8398a3138": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6c489d7a170545dd819f7cee0d7c9f87",
       "placeholder": "​",
       "style": "IPY_MODEL_5711941e04414240bfa8426f57f4ca1e",
       "value": " 200/200 [00:00&lt;00:00, 1995.75it/s]"
      }
     },
     "46860e75262c4210b6fd33a87d9f411e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a27b921ca7e4bea81762b30524246ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "52affebb3fa5435c8420827aeb37c2e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "548dd825cc3f477aa2ad8b65f66c0cb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54c6d8b91a5847c99772163de0505879": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5711941e04414240bfa8426f57f4ca1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "57e67019cfa94114aa7799ac78498d92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8b8897f258404527bfd0c0708ab6c246",
       "placeholder": "​",
       "style": "IPY_MODEL_6463792fe7134328bd94a196b9684ab9",
       "value": " 25/25 [00:01&lt;00:00, 24.62it/s]"
      }
     },
     "594c539dd8fc4563b35d068cf182dae0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e1ce7ba6832e4b7ea70dcd039409f000",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ff5a54fe0d774dddb70e001b2e08bbdb",
       "value": 200.0
      }
     },
     "5c604b7764c3437ab91809d2f213f676": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "607b7e3935674c2eb12a6ebb3b84c4ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "6463792fe7134328bd94a196b9684ab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "64bf5d52fa2a4beb84c67fe131a5b874": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65a6e368225943b3a810957bb8b88de7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "697f02597abe4c368d9f28d852c8499b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_edbacec0135d4775b36aaaea4bda0a72",
        "IPY_MODEL_1849c778434e407896e99bac0c263b95",
        "IPY_MODEL_f4c2b9bb137f4ac5aab34f2e804dfbee"
       ],
       "layout": "IPY_MODEL_4a27b921ca7e4bea81762b30524246ba"
      }
     },
     "6c489d7a170545dd819f7cee0d7c9f87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c9c2dce341347799a27933c4d69254d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e81472ecd1d4618a7242ab93d5c46c6",
       "max": 25.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0be1e245b01f4c06b2f5132ca502f05d",
       "value": 25.0
      }
     },
     "70398ecb836346f3806e874abeea320f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_133d066ef04d4c60b421d1fae5b906f3",
        "IPY_MODEL_c05aba1a6e48410e8f12d7eb76cb0bed",
        "IPY_MODEL_d02f6224519a4538ac78b3abe9f97eaf"
       ],
       "layout": "IPY_MODEL_64bf5d52fa2a4beb84c67fe131a5b874"
      }
     },
     "7156d80c84a94d1db76f48bb8f35bd28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "74414ee9d5c5481aa249f58b85fe717a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_37e22db016c8423e9d1d386c1cd22386",
        "IPY_MODEL_dff7fd0adbb947218f4eeec9ea9bdf8d",
        "IPY_MODEL_ab706ff07df5425abd05e27316e4c720"
       ],
       "layout": "IPY_MODEL_5c604b7764c3437ab91809d2f213f676"
      }
     },
     "7545d8b995a642648d0a2446b10dc310": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_17e9331b7ee84a95b9cfb7ceb1f2ed7f",
        "IPY_MODEL_594c539dd8fc4563b35d068cf182dae0",
        "IPY_MODEL_9e41afbc3fd049ccbe414c326a015e05"
       ],
       "layout": "IPY_MODEL_607b7e3935674c2eb12a6ebb3b84c4ce"
      }
     },
     "7855ce52cb704561a6dd9d97c76c6f90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b5c6954d5884f6ea4629caa1c98e3c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_205ff1eddc254c7fbbecbb6e9203d85f",
        "IPY_MODEL_f71360ea6710407ea59132436cee6a53",
        "IPY_MODEL_0e9d07b3f0c848c0953e7d372f263d4f"
       ],
       "layout": "IPY_MODEL_7d3a560761eb43c4b52b127c70ae0bbe"
      }
     },
     "7d3a560761eb43c4b52b127c70ae0bbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "879a1e38f287402ea99c116f54729e74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b8897f258404527bfd0c0708ab6c246": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e6e2eac1f694cd78bbb0e1c9324f4e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "91bd63cb6d5c4a43a7802ec4ddfdc9f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9358861862fd475ead0cc7e3f829ac3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "981be822fb774e328dad0affde0cd037": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e41afbc3fd049ccbe414c326a015e05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f84fee04dc0842bdab6f521d44110dd1",
       "placeholder": "​",
       "style": "IPY_MODEL_7156d80c84a94d1db76f48bb8f35bd28",
       "value": " 199/200 [00:35&lt;00:00,  5.87it/s]"
      }
     },
     "a268dfe37ed04ff2af9e287897efef74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_02c72da34a7344978f8b3064fcc32f15",
        "IPY_MODEL_31e04ed84ea6413ca60e08e16917c2e0",
        "IPY_MODEL_43e8d2a129ea4fb4be8411e8398a3138"
       ],
       "layout": "IPY_MODEL_9358861862fd475ead0cc7e3f829ac3f"
      }
     },
     "aabf0e68ab6d4d24a25ef25e68e5cb90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab706ff07df5425abd05e27316e4c720": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cef2c0ef06064f028352aa088aefec6d",
       "placeholder": "​",
       "style": "IPY_MODEL_2f5a5195f30f4aed9f5af428d8fedd91",
       "value": " 200/200 [06:03&lt;00:00,  1.84s/it]"
      }
     },
     "afdb5cce482145989cb39ddc359b11d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afece35321fc4a789e843292023f8151": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f068f47e5d6f48c28a3e7df7d8e7e377",
        "IPY_MODEL_2e64309d471343d2b45b347484224a30",
        "IPY_MODEL_cb014160b51d4a028b3f6a9e0e36dcce"
       ],
       "layout": "IPY_MODEL_52affebb3fa5435c8420827aeb37c2e9"
      }
     },
     "b1fcc46cde204d43a7f3cce94c2730a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2589b41f980426893a94be34000f57d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb814c8ac50440dca6aea9b4e190a8f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "be8e2717e8464620aaf8c5c43aa06a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c05aba1a6e48410e8f12d7eb76cb0bed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_afdb5cce482145989cb39ddc359b11d0",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f540dfe8f1de494ab3ab5e8c59c6e94a",
       "value": 200.0
      }
     },
     "c05f0cc8ee6d49c2b756cf50a6e9e4a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c220551c391b421caf79f820afc5da6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c5c58e42f4fa4fd2aa4158fa314c4aaa",
        "IPY_MODEL_6c9c2dce341347799a27933c4d69254d",
        "IPY_MODEL_57e67019cfa94114aa7799ac78498d92"
       ],
       "layout": "IPY_MODEL_0b200cda1b2b4e5aa039706ccd46c0ac"
      }
     },
     "c2e3b5715d0b417aa977f5b0c87da2cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4351cb7f4b1482d8e7412e5d5acb115": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5c58e42f4fa4fd2aa4158fa314c4aaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_46860e75262c4210b6fd33a87d9f411e",
       "placeholder": "​",
       "style": "IPY_MODEL_8e6e2eac1f694cd78bbb0e1c9324f4e4",
       "value": "100%"
      }
     },
     "c6e1c5f00f8947548145bf129731ed51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cb014160b51d4a028b3f6a9e0e36dcce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_91bd63cb6d5c4a43a7802ec4ddfdc9f1",
       "placeholder": "​",
       "style": "IPY_MODEL_c6e1c5f00f8947548145bf129731ed51",
       "value": " 199/200 [00:35&lt;00:00,  5.89it/s]"
      }
     },
     "cbb2cb2ab31d411dbf280c5bc7757c41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cef2c0ef06064f028352aa088aefec6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d02f6224519a4538ac78b3abe9f97eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c05f0cc8ee6d49c2b756cf50a6e9e4a6",
       "placeholder": "​",
       "style": "IPY_MODEL_dc679503720c441ab2747f2052c6c032",
       "value": " 200/200 [00:00&lt;00:00, 1154.74it/s]"
      }
     },
     "d6a365cc10b14a988632151d2746c218": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dabd85afc8eb4a108dd214f49e25d94a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc679503720c441ab2747f2052c6c032": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dff7fd0adbb947218f4eeec9ea9bdf8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b1fcc46cde204d43a7f3cce94c2730a2",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2aac2b921b0f4f659aeb8038374acc96",
       "value": 200.0
      }
     },
     "e1ce7ba6832e4b7ea70dcd039409f000": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e26bc0470d37446b9e983a8eaf890bd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e60cf39cec994282add3df3ea98d0778": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "edbacec0135d4775b36aaaea4bda0a72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aabf0e68ab6d4d24a25ef25e68e5cb90",
       "placeholder": "​",
       "style": "IPY_MODEL_01280cd46a1a487d8720ad3c23cc04c0",
       "value": "100%"
      }
     },
     "f068f47e5d6f48c28a3e7df7d8e7e377": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01960581a4d9449a935021d8a8ad9ac5",
       "placeholder": "​",
       "style": "IPY_MODEL_17fa6f36542b4299ba7e938d4257d96e",
       "value": "100%"
      }
     },
     "f4c2b9bb137f4ac5aab34f2e804dfbee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dabd85afc8eb4a108dd214f49e25d94a",
       "placeholder": "​",
       "style": "IPY_MODEL_c2e3b5715d0b417aa977f5b0c87da2cd",
       "value": " 200/200 [06:03&lt;00:00,  1.84s/it]"
      }
     },
     "f540dfe8f1de494ab3ab5e8c59c6e94a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f71360ea6710407ea59132436cee6a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65a6e368225943b3a810957bb8b88de7",
       "max": 7.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d6a365cc10b14a988632151d2746c218",
       "value": 7.0
      }
     },
     "f84fee04dc0842bdab6f521d44110dd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fae78d56058d4bd6bc1def709bab2083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ff5a54fe0d774dddb70e001b2e08bbdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
